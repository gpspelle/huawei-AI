{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unknown_configuration(module_size, max_number_modules):\n",
    "    never_seen_config = [[] for i in range(max_number_modules)]\n",
    "    seen_config = list(module_size[1].keys())\n",
    "    for i in range(2, max_number_modules):        \n",
    "        for test_config in list(module_size[i].keys()):\n",
    "            composed_config = list(set(test_config.split(\"-\")))\n",
    "            for module in composed_config:\n",
    "                if module not in seen_config:\n",
    "                    never_seen_config[i].append(test_config)\n",
    "                    break\n",
    "         \n",
    "    return never_seen_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/\"\n",
    "datasets = ['c1', 'c2', 'c3', 'c4']\n",
    "reduced_datasets = ['c1']\n",
    "max_number_modules = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [+] Dataset c1  information\n",
      " [=] Number of different cascades of each size\n",
      " [Cascade size 1]  5  possibilities\n",
      " [Cascade size 2]  7  possibilities\n",
      " [Cascade size 3]  6  possibilities\n",
      " [Cascade size 4]  5  possibilities\n",
      " [Cascade size 5]  4  possibilities\n",
      " [Cascade size 6]  3  possibilities\n",
      " [Cascade size 7]  2  possibilities\n",
      " [Cascade size 8]  1  possibilities\n",
      " [=] Number of unknown cascades of each size\n",
      " [Cascade size 2]  0  unseen\n",
      " [Cascade size 3]  0  unseen\n",
      " [Cascade size 4]  0  unseen\n",
      " [Cascade size 5]  0  unseen\n",
      " [Cascade size 6]  0  unseen\n",
      " [Cascade size 7]  0  unseen\n",
      " [Cascade size 8]  0  unseen\n",
      " [=] Biggest cascade\n",
      " [.] ['EDFA_24.0_20.0-SMF_5.6_0-EDFA_24.0_20.0-SMF_5.2_0-EDFA_24.0_20.0-SMF_0_5.0-EDFA_24.0_20.0-SMF_0_5.4']\n",
      " [=] Cascades of size 1\n",
      " [.] ['EDFA_24.0_20.0', 'SMF_5.6_0', 'SMF_5.2_0', 'SMF_0_5.0', 'SMF_0_5.4']\n",
      " [=] Number of cascades of each size\n",
      " [Cascade size 1]  1728  ocurrences\n",
      " [Cascade size 2]  1512  ocurrences\n",
      " [Cascade size 3]  1296  ocurrences\n",
      " [Cascade size 4]  1080  ocurrences\n",
      " [Cascade size 5]  864  ocurrences\n",
      " [Cascade size 6]  648  ocurrences\n",
      " [Cascade size 7]  432  ocurrences\n",
      " [Cascade size 8]  216  ocurrences\n",
      " [.] Total number of samples: 7776\n",
      " [+] Dataset c2  information\n",
      " [=] Number of different cascades of each size\n",
      " [Cascade size 1]  4  possibilities\n",
      " [Cascade size 2]  6  possibilities\n",
      " [Cascade size 3]  6  possibilities\n",
      " [Cascade size 4]  5  possibilities\n",
      " [Cascade size 5]  4  possibilities\n",
      " [Cascade size 6]  3  possibilities\n",
      " [Cascade size 7]  2  possibilities\n",
      " [Cascade size 8]  1  possibilities\n",
      " [=] Number of unknown cascades of each size\n",
      " [Cascade size 2]  0  unseen\n",
      " [Cascade size 3]  0  unseen\n",
      " [Cascade size 4]  0  unseen\n",
      " [Cascade size 5]  0  unseen\n",
      " [Cascade size 6]  0  unseen\n",
      " [Cascade size 7]  0  unseen\n",
      " [Cascade size 8]  0  unseen\n",
      " [=] Biggest cascade\n",
      " [.] ['EDFA_20.0_0.0-SMF_1.6_0-EDFA_20.0_0.0-SMF_1.3_0-EDFA_20.0_0.0-SMF_0_1.4-EDFA_20.0_0.0-SMF_0_1.4']\n",
      " [=] Cascades of size 1\n",
      " [.] ['EDFA_20.0_0.0', 'SMF_1.6_0', 'SMF_1.3_0', 'SMF_0_1.4']\n",
      " [=] Number of cascades of each size\n",
      " [Cascade size 1]  3328  ocurrences\n",
      " [Cascade size 2]  2912  ocurrences\n",
      " [Cascade size 3]  2496  ocurrences\n",
      " [Cascade size 4]  2080  ocurrences\n",
      " [Cascade size 5]  1664  ocurrences\n",
      " [Cascade size 6]  1248  ocurrences\n",
      " [Cascade size 7]  832  ocurrences\n",
      " [Cascade size 8]  416  ocurrences\n",
      " [.] Total number of samples: 14976\n",
      " [+] Dataset c3  information\n",
      " [=] Number of different cascades of each size\n",
      " [Cascade size 1]  4  possibilities\n",
      " [Cascade size 2]  6  possibilities\n",
      " [Cascade size 3]  6  possibilities\n",
      " [Cascade size 4]  5  possibilities\n",
      " [Cascade size 5]  4  possibilities\n",
      " [Cascade size 6]  3  possibilities\n",
      " [Cascade size 7]  2  possibilities\n",
      " [Cascade size 8]  1  possibilities\n",
      " [=] Number of unknown cascades of each size\n",
      " [Cascade size 2]  0  unseen\n",
      " [Cascade size 3]  0  unseen\n",
      " [Cascade size 4]  0  unseen\n",
      " [Cascade size 5]  0  unseen\n",
      " [Cascade size 6]  0  unseen\n",
      " [Cascade size 7]  0  unseen\n",
      " [Cascade size 8]  0  unseen\n",
      " [=] Biggest cascade\n",
      " [.] ['EDFA_20.0_10.0-SMF_1.6_0-EDFA_20.0_10.0-SMF_1.3_0-EDFA_20.0_10.0-SMF_0_1.4-EDFA_20.0_10.0-SMF_0_1.4']\n",
      " [=] Cascades of size 1\n",
      " [.] ['EDFA_20.0_10.0', 'SMF_1.6_0', 'SMF_1.3_0', 'SMF_0_1.4']\n",
      " [=] Number of cascades of each size\n",
      " [Cascade size 1]  5568  ocurrences\n",
      " [Cascade size 2]  4872  ocurrences\n",
      " [Cascade size 3]  4176  ocurrences\n",
      " [Cascade size 4]  3480  ocurrences\n",
      " [Cascade size 5]  2784  ocurrences\n",
      " [Cascade size 6]  2088  ocurrences\n",
      " [Cascade size 7]  1392  ocurrences\n",
      " [Cascade size 8]  696  ocurrences\n",
      " [.] Total number of samples: 25056\n",
      " [+] Dataset c4  information\n",
      " [=] Number of different cascades of each size\n",
      " [Cascade size 1]  7  possibilities\n",
      " [Cascade size 2]  7  possibilities\n",
      " [Cascade size 3]  6  possibilities\n",
      " [Cascade size 4]  5  possibilities\n",
      " [Cascade size 5]  4  possibilities\n",
      " [Cascade size 6]  3  possibilities\n",
      " [Cascade size 7]  2  possibilities\n",
      " [Cascade size 8]  1  possibilities\n",
      " [=] Number of unknown cascades of each size\n",
      " [Cascade size 2]  0  unseen\n",
      " [Cascade size 3]  0  unseen\n",
      " [Cascade size 4]  0  unseen\n",
      " [Cascade size 5]  0  unseen\n",
      " [Cascade size 6]  0  unseen\n",
      " [Cascade size 7]  0  unseen\n",
      " [Cascade size 8]  0  unseen\n",
      " [=] Biggest cascade\n",
      " [.] ['EDFA_20.0_0.0-SMF_1.6_0-EDFA_20.0_17.0-SMF_1.3_0-EDFA_20.0_18.0-SMF_0_1.4-EDFA_20.0_20.0-SMF_0_1.4']\n",
      " [=] Cascades of size 1\n",
      " [.] ['EDFA_20.0_0.0', 'SMF_1.6_0', 'EDFA_20.0_17.0', 'SMF_1.3_0', 'EDFA_20.0_18.0', 'SMF_0_1.4', 'EDFA_20.0_20.0']\n",
      " [=] Number of cascades of each size\n",
      " [Cascade size 1]  6560  ocurrences\n",
      " [Cascade size 2]  5740  ocurrences\n",
      " [Cascade size 3]  4920  ocurrences\n",
      " [Cascade size 4]  4100  ocurrences\n",
      " [Cascade size 5]  3280  ocurrences\n",
      " [Cascade size 6]  2460  ocurrences\n",
      " [Cascade size 7]  1640  ocurrences\n",
      " [Cascade size 8]  820  ocurrences\n",
      " [.] Total number of samples: 29520\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    \n",
    "    module_size = [{} for i in range(max_number_modules)]\n",
    "        \n",
    "    dataset_folder = os.path.join(data_folder, dataset)\n",
    "    X = pickle.load(open(dataset_folder + \"/X.pkl\", \"rb\"))\n",
    "    y = pickle.load(open(dataset_folder + \"/y.pkl\", \"rb\"))\n",
    "    \n",
    "    for x_, y_ in zip(X, y):\n",
    "        sequence_size = len(x_[0])\n",
    "        dict_key = \"\"\n",
    "        for i in range(sequence_size):\n",
    "            dict_key += (x_[0][i][0] + \"_\" +str(x_[0][i][1][0]) + \"_\" + str(x_[0][i][1][1]) + \"-\")\n",
    "        \n",
    "        dict_key = dict_key[:-1]\n",
    "        try:\n",
    "            module_size[sequence_size][dict_key].append([x_[1], list(y_)])\n",
    "        except:\n",
    "            module_size[sequence_size][dict_key] = [[x_[1], list(y_)]]\n",
    "    \n",
    "    print(\" [+] Dataset\", dataset, \" information\")\n",
    "    print(\" [=] Number of different cascades of each size\")\n",
    "    for i in range(1, max_number_modules):\n",
    "        different_cascades = len(list(module_size[i].keys()))\n",
    "        print(\" [Cascade size \" + str(i) + \"] \", different_cascades, \" possibilities\")\n",
    "        \n",
    "    \n",
    "    # A known cascade is is composed of modules already seen alone in cascades\n",
    "    # of size 1. Thus, an unkown cascade contain modules that weren't found alone\n",
    "    # in cascades of size 1.\n",
    "    never_seen_config = unknown_configuration(module_size, max_number_modules)\n",
    "    print(\" [=] Number of unknown cascades of each size\")\n",
    "    for i in range(2, max_number_modules):\n",
    "        never_seen = len(never_seen_config[i])\n",
    "        print(\" [Cascade size \" + str(i) + \"] \", never_seen, \" unseen\")\n",
    "        \n",
    "    \n",
    "    print(\" [=] Biggest cascade\")\n",
    "    print(\" [.]\", list(module_size[8].keys()))\n",
    "    \n",
    "    print(\" [=] Cascades of size 1\")\n",
    "    print(\" [.]\", list(module_size[1].keys()))\n",
    "\n",
    "    print(\" [=] Number of cascades of each size\")\n",
    "    total_total = 0\n",
    "    for i in range(1, max_number_modules):\n",
    "        total_elem = 0\n",
    "        for key in list(module_size[i].keys()):\n",
    "            total_elem += len(module_size[i][key])\n",
    "        total_total += total_elem\n",
    "        print(\" [Cascade size \" + str(i) + \"] \", total_elem, \" ocurrences\")\n",
    "    print(\" [.] Total number of samples:\", total_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
